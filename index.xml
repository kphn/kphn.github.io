<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>有鸟止南方之阜</title>
    <link>https://kphn.github.io/</link>
    <description>Recent content on 有鸟止南方之阜</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 24 Aug 2019 22:12:12 +0800</lastBuildDate>
    
        <atom:link href="https://kphn.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>关于</title>
      <link>https://kphn.github.io/about/</link>
      <pubDate>Thu, 20 Jun 2019 21:38:52 +0800</pubDate>
      
      <guid>https://kphn.github.io/about/</guid>
      
        <description>&lt;p&gt;记录学习生活感悟的Blog，之前写的东西都比较零碎且没有全部记录在博客中。
希望之后能认真的耕耘好着一亩三分地，认真记录好整理好自己的学习心得。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Redis Bitmap</title>
      <link>https://kphn.github.io/post/2019/redis-bitmap/</link>
      <pubDate>Sat, 24 Aug 2019 22:12:12 +0800</pubDate>
      
      <guid>https://kphn.github.io/post/2019/redis-bitmap/</guid>
      
        <description>

&lt;h2 id=&#34;redis-bitmap简介&#34;&gt;redis bitmap简介&lt;/h2&gt;

&lt;p&gt;redis中的bitmap是一串连续的2进制数字，每一位所在的位置为偏移，在bitmap上可以执行AND，OR，XOR，NOT等位操作。&lt;/p&gt;

&lt;p&gt;bitmap中保存每个位置的数据仅使用了一个bit，而对应的数据的存储根据大小在bitmap中相对应offset。&lt;/p&gt;

&lt;p&gt;一个简单的例子：日活跃用户&lt;/p&gt;

&lt;p&gt;​    为了统计今日登录的用户数，我们建立了一个bitmap,每一位标识一个用户ID。当某个用户访问我们的网页或执行了某个操作，就在bitmap中把标识此用户的位置为1。在Redis中获取此bitmap的key值是通过用户执行操作的类型和时间戳获得的。之后可以通过各天的bitmap进行位操作来统计相应的数据。&lt;/p&gt;

&lt;p&gt;在这里，bitmap在大数据量的情况下，占用大小较为稳定，增长不会随着存储数据量线性增长。也不会只存储一个 2^32-1数字就占满 512G（存在着内存压缩）。&lt;/p&gt;

&lt;h2 id=&#34;bitmap-vs-hash&#34;&gt;bitmap vs hash&lt;/h2&gt;

&lt;p&gt;在数据量没有那么大的情况下，使用bitmap可能比使用hashmap还要占用空间。因此，做了如下的实验来验证各个数据存储量的情况下，bitmap与hash占用的空间大小。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func testBit(c redis.Conn, times int) int {	//times为测试存储量
	for i := 0; i &amp;lt; times; i = i + 1000 {
		for j := 0; j &amp;lt; 1000; j++ {		//redis pipeline
			c.Send(&amp;quot;setbit&amp;quot;, &amp;quot;bitset&amp;quot;, rand.Intn(maxUsers), 1)	//使数据尽量分散，减小压缩带来的占用降低
		}
		c.Flush()
	}

	res, _ := redis.String(c.Do(&amp;quot;debug&amp;quot;, &amp;quot;object&amp;quot;, &amp;quot;bitset&amp;quot;))
	return getLength(res)
}

func testHash(c redis.Conn, times int) int {
	for i := 0; i &amp;lt; times; i += 1000 {
		args := make([]interface{}, 0)
		args = append(args, &amp;quot;hash&amp;quot;)
		for j := 0; j &amp;lt; 1000; j++ {	//redis mset
			args = append(args, i+j+times)
			args = append(args, 1)
		}
		c.Do(&amp;quot;HSET&amp;quot;, args...)
	}
	res, _ := redis.String(c.Do(&amp;quot;debug&amp;quot;, &amp;quot;object&amp;quot;, &amp;quot;hash&amp;quot;))
	return getLength(res)
}

func getLength(s string) int {			//获取debug命令中占用空间量
	strs := strings.Fields(s)
	length := strings.Split(strs[4], &amp;quot;:&amp;quot;)[1]
	l, _ := strconv.Atoi(length)
	return l
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实际测试代码，测试少量数据情况下【100~100000】及大量数据情况下的【100000，10000000】情况下的实际空间大小，并使用gonum/plot绘制出效果图：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;const maxUsers = 200000000		//假设公司有两亿用户

func main() {
	c, err := redis.Dial(&amp;quot;tcp&amp;quot;, &amp;quot;:6379&amp;quot;)
	if err != nil {
		fmt.Println(&amp;quot;err:&amp;quot;, err)
		return
	}
	defer c.Close()
	p, _ := plot.New()
	p.Title.Text = &amp;quot;bitmap vs hash&amp;quot;
	p.X.Label.Text = &amp;quot;key nums&amp;quot;
	p.Y.Label.Text = &amp;quot;memory used&amp;quot;

	points := plotter.XYs{}
	points1 := plotter.XYs{}

	timess := []int{100, 1000, 2000, 5000, 10000, 30000, 45000, 60000, 100000}
	afterTest(c)
	for _, times := range timess {
		points = append(points, plotter.XY{float64(times), float64(testBit(c, times))})
		points1 = append(points1, plotter.XY{float64(times), float64(testHash(c, times))})
		afterTest(c)
	}
	plotutil.AddLinePoints(p, []interface{}{points, points1}...)
	p.Save(4*vg.Inch, 4*vg.Inch, &amp;quot;small.png&amp;quot;)

	points3 := plotter.XYs{}
	points4 := plotter.XYs{}

	timess = []int{100000, 300000, 1000000, 2000000, 3000000, 10000000}
	afterTest(c)
	for _, times := range timess {
		points3 = append(points3, plotter.XY{float64(times), float64(testBit(c, times))})
		points4 = append(points4, plotter.XY{float64(times), float64(testHash(c, times))})
		afterTest(c)
	}
	plotutil.AddLinePoints(p, []interface{}{points3, points4}...)
	p.Save(4*vg.Inch, 4*vg.Inch, &amp;quot;large.png&amp;quot;)
}

func afterTest(c redis.Conn) {
	c.Do(&amp;quot;del&amp;quot;, &amp;quot;bitset&amp;quot;)
	c.Do(&amp;quot;del&amp;quot;, &amp;quot;hash&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实验结果如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kphn.github.io/image/small.png&#34; alt=&#34;小规模数据&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在假定两亿用户的情况下，小规模数据测试情况下，可以发现6W左右数据存储的情况下，hash 和 bitmap使用的空间都为400~500KB，而用户小于6W的情况下使用hash稍有优势。而数据规模更大的时候，bitmap的存储优势就发挥了出来。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kphn.github.io/image/large.png&#34; alt=&#34;大规模数据&#34; /&gt;&lt;/p&gt;

&lt;p&gt;大规模场景下可以看出hash的空间占用为线性增长，而bitmap在大规模数据存储的情况下空间占用量的增长则稳定的多。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Redis 数据结构</title>
      <link>https://kphn.github.io/post/2019/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</link>
      <pubDate>Tue, 23 Jul 2019 14:24:45 +0800</pubDate>
      
      <guid>https://kphn.github.io/post/2019/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</guid>
      
        <description>

&lt;h2 id=&#34;数据结构&#34;&gt;数据结构&lt;/h2&gt;

&lt;h3 id=&#34;sds-simple-dynamic-strings&#34;&gt;SDS/simple dynamic strings&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;struct sdshdr {

    // 记录 buf 数组中已使用字节的数量
    // 等于 SDS 所保存字符串的长度
    int len;

    // 记录 buf 数组中未使用字节的数量
    int free;

    // 字节数组，用于保存字符串
    char buf[];

};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://redisbook.com/_images/graphviz-72760f6945c3742eca0df91a91cc379168eda82d.png&#34; alt=&#34;SDS实例&#34; /&gt;&lt;/p&gt;

&lt;p&gt;SDS遵循C语言的规则，在字符串末尾添加了&amp;rsquo;\0&amp;rsquo;,这样就可以直接使用C字符串函数库中的函数。&lt;/p&gt;

&lt;p&gt;SDS保存了字符串的长度，这样可以在常数时间内获取字符串的长度。&lt;/p&gt;

&lt;p&gt;SDS在字符串扩展时可以自动扩展申请的字符串长度，这样可以避免发生缓冲区溢出的可能性。&lt;/p&gt;

&lt;p&gt;SDS中存在着free空间【空间预分配和惰性删除】，可以尽量减少内存的重分配。&lt;/p&gt;

&lt;p&gt;SDS也是二进制安全的，因此也可以用来保存二进制数据。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;C字符串&lt;/th&gt;
&lt;th&gt;SDS&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;获取字符串长度的复杂度为O(N)&lt;/td&gt;
&lt;td&gt;获取字符串长度的复杂度为O(1)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;API是不安全的，可能会造成缓冲区溢出&lt;/td&gt;
&lt;td&gt;API是安全的，不会造成缓冲区溢出&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;修改字符串长度N次必然需要执行N此内存分配&lt;/td&gt;
&lt;td&gt;修改字符串长度N次至多执行N次内存分配&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;只能保存文本数据&lt;/td&gt;
&lt;td&gt;可以保存文本或者二进制数据&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;可以使用所有&lt;string.h&gt;库中的函数&lt;/td&gt;
&lt;td&gt;可以使用一部分&lt;string.h&gt;库中的函数&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;链表&#34;&gt;链表&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct listNode {

    // 前置节点
    struct listNode *prev;

    // 后置节点
    struct listNode *next;

    // 节点的值
    void *value;

} listNode;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://redisbook.com/_images/graphviz-167adfc2e52e078d4c0e3c8a9eddec54551602fb.png&#34; alt=&#34;list&#34; /&gt;&lt;/p&gt;

&lt;p&gt;虽然使用多个listNode结构就可以组成链表，但是使用adlist.h/list 来持有链表的话，操作起来会更加方便。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct list {

    // 表头节点
    listNode *head;

    // 表尾节点
    listNode *tail;

    // 链表所包含的节点数量
    unsigned long len;

    // 节点值复制函数
    void *(*dup)(void *ptr);

    // 节点值释放函数
    void (*free)(void *ptr);

    // 节点值对比函数
    int (*match)(void *ptr, void *key);

} list;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://redisbook.com/_images/graphviz-5f4d8b6177061ac52d0ae05ef357fceb52e9cb90.png&#34; alt=&#34;list&#34; /&gt;&lt;/p&gt;

&lt;p&gt;redis链表实现了如下的特性:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;双端：链表节点带有prev和next指针，获取某个节点的前置节点和后置节点的复杂度都是O(1)&lt;/li&gt;
&lt;li&gt;无环：表头节点的prev指针和表尾节点的next指针都指向NIULL，对链表的访问以NULL为终点&lt;/li&gt;
&lt;li&gt;带表头指针和表尾指针：通过list结果的head和tail指针，程序获取链表头结点和尾节点的复杂度为O(1)&lt;/li&gt;
&lt;li&gt;带链表长度计数器：程序使用list结构的len属性来对list持有的链表节点进行计数，程序获取链表中节点数量的复杂度为O(1)&lt;/li&gt;
&lt;li&gt;多态：链表节点使用void*指针来保存节点值，并且可以通过list结构的dup、free、match三个属性为节点值设置类型特定函数，所以链表可以保存各种不同类型的值。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;redis队列主要可以用来做消息队列，发布订阅pub/sub，列表键，慢查询，监视器等。做消息队列的话，由于没有实现ack机制，且在宕机时可能会有部分数据没有持久化，对数据可靠性要求较高的场景不适合使用redis list来做消息队列。&lt;/p&gt;

&lt;h3 id=&#34;字典&#34;&gt;字典&lt;/h3&gt;

&lt;p&gt;redis字典使用的哈希表由 dictht结构定义：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct dictht {

    // 哈希表数组
    dictEntry **table;

    // 哈希表大小
    unsigned long size;

    // 哈希表大小掩码，用于计算索引值
    // 总是等于 size - 1
  	// size 总是为2的整数倍
    unsigned long sizemask;

    // 该哈希表已有节点的数量
    unsigned long used;

} dictht;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;table&lt;/code&gt; 属性是一个数组， 数组中的每个元素都是一个指向 &lt;code&gt;dict.h/dictEntry&lt;/code&gt; 结构的指针， 每个 &lt;code&gt;dictEntry&lt;/code&gt; 结构保存着一个键值对。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;size&lt;/code&gt; 属性记录了哈希表的大小， 也即是 &lt;code&gt;table&lt;/code&gt; 数组的大小， 而 &lt;code&gt;used&lt;/code&gt; 属性则记录了哈希表目前已有节点（键值对）的数量。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sizemask&lt;/code&gt; 属性的值总是等于 &lt;code&gt;size - 1&lt;/code&gt; ， 这个属性和哈希值一起决定一个键应该被放到 &lt;code&gt;table&lt;/code&gt; 数组的哪个索引上面。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://redisbook.com/_images/graphviz-bd3eecd927a4d8fc33b4a1c7f5957c52d67c5021.png&#34; alt=&#34;table&#34; /&gt;&lt;/p&gt;

&lt;p&gt;哈希表节点使用 &lt;code&gt;dictEntry&lt;/code&gt; 结构表示， 每个 &lt;code&gt;dictEntry&lt;/code&gt; 结构都保存着一个键值对：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct dictEntry {

    // 键
    void *key;

    // 值
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
    } v;

    // 指向下个哈希表节点，形成链表
    struct dictEntry *next;

} dictEntry;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;key&lt;/code&gt; 属性保存着键值对中的键， 而 &lt;code&gt;v&lt;/code&gt; 属性则保存着键值对中的值， 其中键值对的值可以是一个指针， 或者是一个 &lt;code&gt;uint64_t&lt;/code&gt; 整数， 又或者是一个 &lt;code&gt;int64_t&lt;/code&gt; 整数。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;next&lt;/code&gt; 属性是指向另一个哈希表节点的指针， 这个指针可以将多个哈希值相同的键值对连接在一次， 以此来解决键冲突（collision）的问题。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://redisbook.com/_images/graphviz-d2641d962325fd58bf15d9fffb4208f70251a999.png&#34; alt=&#34;dictEntry&#34; /&gt;&lt;/p&gt;

&lt;p&gt;而字典的结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct dict {

    // 类型特定函数
    dictType *type;

    // 私有数据
    void *privdata;

    // 哈希表
    dictht ht[2];	//ht[0]表示哈希表，ht[1]只有在哈希表进行rehash时使用。

    // rehash 索引
    // 当 rehash 不在进行时，值为 -1
    int rehashidx; /* rehashing not in progress if rehashidx == -1 */

} dict;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;rehash&#34;&gt;rehash&lt;/h3&gt;

&lt;p&gt;随着操作的不断执行， 哈希表保存的键值对会逐渐地增多或者减少， 为了让哈希表的负载因子（load factor）维持在一个合理的范围之内， 当哈希表保存的键值对数量太多或者太少时， 程序需要对哈希表的大小进行相应的扩展或者收缩。&lt;/p&gt;

&lt;p&gt;扩展和收缩哈希表的工作可以通过执行 rehash 【渐进式】（重新散列）操作来完成， Redis 对字典的哈希表执行 rehash 的步骤如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;为 &lt;code&gt;ht[1]&lt;/code&gt; 分配空间， 让字典同时持有 &lt;code&gt;ht[0]&lt;/code&gt; 和 &lt;code&gt;ht[1]&lt;/code&gt; 两个哈希表。&lt;/li&gt;
&lt;li&gt;在字典中维持一个索引计数器变量 &lt;code&gt;rehashidx&lt;/code&gt; ， 并将它的值设置为 &lt;code&gt;0&lt;/code&gt; ， 表示 rehash 工作正式开始。&lt;/li&gt;
&lt;li&gt;在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 &lt;code&gt;ht[0]&lt;/code&gt; 哈希表在 &lt;code&gt;rehashidx&lt;/code&gt; 索引上的所有键值对 rehash 到 &lt;code&gt;ht[1]&lt;/code&gt; ， 当 rehash 工作完成之后， 程序将 &lt;code&gt;rehashidx&lt;/code&gt; 属性的值增一。&lt;/li&gt;
&lt;li&gt;随着字典操作的不断执行， 最终在某个时间点上， &lt;code&gt;ht[0]&lt;/code&gt; 的所有键值对都会被 rehash 至 &lt;code&gt;ht[1]&lt;/code&gt; ， 这时程序将 &lt;code&gt;rehashidx&lt;/code&gt; 属性的值设为 &lt;code&gt;-1&lt;/code&gt; ， 表示 rehash 操作已完成。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;跳跃表&#34;&gt;跳跃表&lt;/h3&gt;

&lt;p&gt;跳跃表用来实现 zset，跳跃表【zskiplist】主要有以下几个属性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;header&lt;/code&gt; ：指向跳跃表的表头节点。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tail&lt;/code&gt; ：指向跳跃表的表尾节点。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;level&lt;/code&gt; ：记录目前跳跃表内，层数最大的那个节点的层数（表头节点的层数不计算在内）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;length&lt;/code&gt; ：记录跳跃表的长度，也即是，跳跃表目前包含节点的数量（表头节点不计算在内）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://redisbook.com/_images/graphviz-8fc5de396a5b52c3d0b1991a1e09558ad055dd86.png&#34; alt=&#34;skip list&#34; /&gt;&lt;/p&gt;

&lt;p&gt;zskiplist结构hea的和tail指向的是 zskiplistNode结构，该结构包含以下属性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;层（level）：节点中用 &lt;code&gt;L1&lt;/code&gt; 、 &lt;code&gt;L2&lt;/code&gt; 、 &lt;code&gt;L3&lt;/code&gt; 等字样标记节点的各个层， &lt;code&gt;L1&lt;/code&gt; 代表第一层， &lt;code&gt;L2&lt;/code&gt; 代表第二层，以此类推。每个层都带有两个属性：前进指针和跨度。前进指针用于访问位于表尾方向的其他节点，而跨度则记录了前进指针所指向节点和当前节点的距离。在上面的图片中，连线上带有数字的箭头就代表前进指针，而那个数字就是跨度。当程序从表头向表尾进行遍历时，访问会沿着层的前进指针进行。&lt;/li&gt;
&lt;li&gt;后退（backward）指针：节点中用 &lt;code&gt;BW&lt;/code&gt; 字样标记节点的后退指针，它指向位于当前节点的前一个节点。后退指针在程序从表尾向表头遍历时使用。&lt;/li&gt;
&lt;li&gt;分值（score）：各个节点中的 &lt;code&gt;1.0&lt;/code&gt; 、 &lt;code&gt;2.0&lt;/code&gt; 和 &lt;code&gt;3.0&lt;/code&gt; 是节点所保存的分值。在跳跃表中，节点按各自所保存的分值从小到大排列。&lt;/li&gt;
&lt;li&gt;成员对象（obj）：各个节点中的 &lt;code&gt;o1&lt;/code&gt; 、 &lt;code&gt;o2&lt;/code&gt; 和 &lt;code&gt;o3&lt;/code&gt; 是节点所保存的成员对象。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总结：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;跳跃表是有序集合的底层实现之一， 除此之外它在 Redis 中没有其他应用。&lt;/li&gt;
&lt;li&gt;Redis 的跳跃表实现由 &lt;code&gt;zskiplist&lt;/code&gt; 和 &lt;code&gt;zskiplistNode&lt;/code&gt; 两个结构组成， 其中 &lt;code&gt;zskiplist&lt;/code&gt; 用于保存跳跃表信息（比如表头节点、表尾节点、长度）， 而 &lt;code&gt;zskiplistNode&lt;/code&gt; 则用于表示跳跃表节点。&lt;/li&gt;
&lt;li&gt;每个跳跃表节点的层高都是 &lt;code&gt;1&lt;/code&gt; 至 &lt;code&gt;32&lt;/code&gt; 之间的随机数。&lt;/li&gt;
&lt;li&gt;在同一个跳跃表中， 多个节点可以包含相同的分值， 但每个节点的成员对象必须是唯一的。&lt;/li&gt;
&lt;li&gt;跳跃表中的节点按照分值大小进行排序， 当分值相同时， 节点按照成员对象的大小进行排序。&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>分布式锁</title>
      <link>https://kphn.github.io/post/2019/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</link>
      <pubDate>Fri, 05 Jul 2019 08:05:08 +0800</pubDate>
      
      <guid>https://kphn.github.io/post/2019/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</guid>
      
        <description>

&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;

&lt;p&gt;在分布式环境下，需要控制多个节点对同一个资源的并发访问，此时本地的加锁已经不能满足需要。为了实现在分布式环境下的锁。&lt;/p&gt;

&lt;h3 id=&#34;使用场景&#34;&gt;使用场景&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;效率:使用分布式锁可以避免不同节点重复相同的工作，这些工作会浪费资源。比如用户付了钱之后有可能不同节点会发出多封短信。&lt;/li&gt;
&lt;li&gt;正确性:加分布式锁同样可以避免破坏正确性的发生，如果两个节点在同一条数据上面操作，比如多个节点机器对同一个订单操作不同的流程有可能会导致该笔订单最后状态出现错误，造成损失。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;特点&#34;&gt;特点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;互斥性:和我们本地锁一样互斥性是最基本，但是分布式锁需要保证在不同节点的不同线程的互斥。&lt;/li&gt;
&lt;li&gt;可重入性:同一个节点上的同一个线程如果获取了锁之后那么也可以再次获取这个锁。&lt;/li&gt;
&lt;li&gt;锁超时:和本地锁一样支持锁超时，防止死锁。&lt;/li&gt;
&lt;li&gt;高效，高可用:加锁和解锁需要高效，同时也需要保证高可用防止分布式锁失效，可以增加降级。&lt;/li&gt;
&lt;li&gt;支持阻塞和非阻塞:和ReentrantLock一样支持lock和trylock以及tryLock(long timeOut)。&lt;/li&gt;
&lt;li&gt;支持公平锁和非公平锁(可选):公平锁的意思是按照请求加锁的顺序获得锁，非公平锁就相反是无序的。这个一般来说实现的比较少。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;常见实现方式&#34;&gt;常见实现方式&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;MySql&lt;/li&gt;
&lt;li&gt;ZK/etcd&lt;/li&gt;
&lt;li&gt;Redis&lt;/li&gt;
&lt;li&gt;Chubby&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;mysql&#34;&gt;mysql&lt;/h2&gt;

&lt;h3 id=&#34;事务&#34;&gt;事务&lt;/h3&gt;

&lt;p&gt;利用mysql的事务可以实现分布式资源的互斥访问，一般可以建立一个锁表。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE TABLE `lock_table` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `resourcce_name` varchar(128) DEFAULT &#39;&#39;&#39;&#39;&#39;&#39; COMMENT &#39;资源名称&#39;,
  `node_info` varchar(128) DEFAULT NULL COMMENT &#39;机器信息&#39;,
  `count` int(11) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;锁的次数，统计可重入锁&#39;,
  `desc` varchar(128) DEFAULT NULL COMMENT &#39;额外的描述信息&#39;,
  `utime` int(11) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;更新时间戳&#39;,
  `ctime` int(11) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;创建时间戳&#39;,
  PRIMARY KEY (`id`),
  UNIQUE KEY `uniq_resource` (`resourcce_name`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Lock&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Transcation
public void lock(resourceName){
  if (select * from lock_table where resource_name = resourceName;有数据){
    if(node_info == currentNode){
      update lock_table set count=count+1 where resource_name = resourceName；
      return true；
    }else{
      return false;
    }
  }else{
    insert into lock_table;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;利用了sql的事务，获取锁时，先去查询锁是否存在，如果存在则比较node_info【ip+线程id】是否一致。如果一致就加可重入锁count的值，如果不一致那么就返回false。如果没有值，则可以创建这个锁。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;tryLock:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public boolean tryLock(){
  return mysqlLock.lock();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;tryLock(timeout)&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public boolean tryLock(long timeout){
  long endtime = timenow + timeout;
  while(true){
    if mysqlLock.lock(){
      return true;
    }
    if(timenow &amp;gt; endtime){
      return false;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;unlock()&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Transcation
public boolean unlock(){
  if(select * from lock_table 有数据){
    if(currentNode == node_info){
      if (count&amp;gt;1){
        update count = count-1;
      }else{
        delete;
      }
    }else{
      return false;
    }
  }else{
    return false;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;锁超时&lt;/strong&gt;：如果持有锁的节点挂了，那么该锁就不会被释放，我们可以启动一个定时任务来认定节点挂了之后释放锁。&lt;/p&gt;

&lt;h2 id=&#34;etcd&#34;&gt;etcd&lt;/h2&gt;

&lt;h3 id=&#34;事务-1&#34;&gt;事务&lt;/h3&gt;

&lt;p&gt;etcd3中可以序列化多个操作为一个条件性的迷你事务。每个事务包含一组条件守护的组合，当所有提交满足时一组操作被执行，并且任何条件不满足时另外一组操作被执行。事务可以保证分布式锁的安全。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;Txn().If(cond1, cond2, ...).Then(op1, op2, ...,).Else(op1’, op2’, …)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;etcd3中的事务有三个部分，条件块，&lt;code&gt;If(cond1,cond2,...)&lt;/code&gt; ,成功块 &lt;code&gt;Then(op1,op2,...)&lt;/code&gt;,失败块&lt;code&gt;Else(op1,op2,...)&lt;/code&gt; 条件块中的所有条件都满足的情况下就执行Then，否则就执行Else。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func doTxnXfer(etcd *v3.Client, from, to string, amount uint) (bool, error) {
    getresp, err := etcd.Txn(ctx.TODO()).Then(OpGet(from), OpGet(to)).Commit()	//事务查出from和get
    if err != nil {
         return false, err
    }
    fromKV := getresp.Responses[0].GetRangeResponse().Kvs[0]
    toKV := getresp.Responses[1].GetRangeResponse().Kvs[1]
    fromV, toV := toUInt64(fromKV.Value), toUint64(toKV.Value)
    if fromV &amp;lt; amount {
        return false, fmt.Errorf(“insufficient value”)
    }
    txn := etcd.Txn(ctx.TODO()).If(
        v3.Compare(v3.ModRevision(from), “=”, fromKV.ModRevision),
        v3.Compare(v3.ModRevision(to), “=”, toKV.ModRevision))			//如果from 和 get还没被修改
    txn = txn.Then(
        OpPut(from, fromUint64(fromV - amount)),					//那么久同时更新这两个key
        OpPut(to, fromUint64(toV + amount))
    putresp, err := txn.Commit()												//提交事务
    if err != nil {
        return false, err
    }
    return putresp.Succeeded, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://coreos.com/sites/default/files/inline-images/diagram3.png&#34; alt=&#34;diagram&#34; /&gt;&lt;/p&gt;

&lt;p&gt;而利用etcd的事务实现分布式锁的代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package concurrency

import (
	&amp;quot;context&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;sync&amp;quot;

	v3 &amp;quot;go.etcd.io/etcd/clientv3&amp;quot;
	pb &amp;quot;go.etcd.io/etcd/etcdserver/etcdserverpb&amp;quot;
)

// Mutex implements the sync Locker interface with etcd
type Mutex struct {
	s *Session

	pfx   string
	myKey string
	myRev int64
	hdr   *pb.ResponseHeader
}

func NewMutex(s *Session, pfx string) *Mutex {
	return &amp;amp;Mutex{s, pfx + &amp;quot;/&amp;quot;, &amp;quot;&amp;quot;, -1, nil}
}

// Lock locks the mutex with a cancelable context. If the context is canceled
// while trying to acquire the lock, the mutex tries to clean its stale lock entry.
func (m *Mutex) Lock(ctx context.Context) error {
	s := m.s
	client := m.s.Client()

	m.myKey = fmt.Sprintf(&amp;quot;%s%x&amp;quot;, m.pfx, s.Lease())
	cmp := v3.Compare(v3.CreateRevision(m.myKey), &amp;quot;=&amp;quot;, 0)
	// put self in lock waiters via myKey; oldest waiter holds lock
	put := v3.OpPut(m.myKey, &amp;quot;&amp;quot;, v3.WithLease(s.Lease()))
	// reuse key in case this session already holds the lock
	get := v3.OpGet(m.myKey)
	// fetch current holder to complete uncontended path with only one RPC
	getOwner := v3.OpGet(m.pfx, v3.WithFirstCreate()...)
	resp, err := client.Txn(ctx).If(cmp).Then(put, getOwner).Else(get, getOwner).Commit()
  //类似于原子操作cas，compare and swap
	if err != nil {
		return err
	}
	m.myRev = resp.Header.Revision
	if !resp.Succeeded {
		m.myRev = resp.Responses[0].GetResponseRange().Kvs[0].CreateRevision
	}
	// if no key on prefix / the minimum rev is key, already hold the lock
	ownerKey := resp.Responses[1].GetResponseRange().Kvs
	if len(ownerKey) == 0 || ownerKey[0].CreateRevision == m.myRev {
		m.hdr = resp.Header
		return nil
	}

	// wait for deletion revisions prior to myKey
	hdr, werr := waitDeletes(ctx, client, m.pfx, m.myRev-1)
	// release lock key if wait failed
	if werr != nil {
		m.Unlock(client.Ctx())
	} else {
		m.hdr = hdr
	}
	return werr
}

func (m *Mutex) Unlock(ctx context.Context) error {
	client := m.s.Client()
	if _, err := client.Delete(ctx, m.myKey); err != nil {
		return err
	}
	m.myKey = &amp;quot;\x00&amp;quot;
	m.myRev = -1
	return nil
}

func (m *Mutex) IsOwner() v3.Cmp {
	return v3.Compare(v3.CreateRevision(m.myKey), &amp;quot;=&amp;quot;, m.myRev)
}

func (m *Mutex) Key() string { return m.myKey }

// Header is the response header received from etcd on acquiring the lock.
func (m *Mutex) Header() *pb.ResponseHeader { return m.hdr }

type lockerMutex struct{ *Mutex }

func (lm *lockerMutex) Lock() {
	client := lm.s.Client()
	if err := lm.Mutex.Lock(client.Ctx()); err != nil {
		panic(err)
	}
}
func (lm *lockerMutex) Unlock() {
	client := lm.s.Client()
	if err := lm.Mutex.Unlock(client.Ctx()); err != nil {
		panic(err)
	}
}

// NewLocker creates a sync.Locker backed by an etcd mutex.
func NewLocker(s *Session, pfx string) sync.Locker {
	return &amp;amp;lockerMutex{NewMutex(s, pfx)}
}

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;redis&#34;&gt;redis&lt;/h2&gt;

&lt;h3 id=&#34;单节点redis锁&#34;&gt;单节点redis锁&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;SET resource_name my_random_value NX PX 30000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在上面的&lt;code&gt;SET&lt;/code&gt;命令中：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;my_random_value&lt;/code&gt;是由客户端生成的一个随机字符串，它要保证在足够长的一段时间内在所有客户端的所有获取锁的请求中都是唯一的。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NX&lt;/code&gt;表示只有当&lt;code&gt;resource_name&lt;/code&gt;对应的key值不存在的时候才能&lt;code&gt;SET&lt;/code&gt;成功。这保证了只有第一个请求的客户端才能获得锁，而其它客户端在锁被释放之前都无法获得锁。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PX 30000&lt;/code&gt;表示这个锁有一个30秒的自动过期时间。当然，这里30秒只是一个例子，客户端可以选择合适的过期时间。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最后，当客户端完成了对共享资源的操作之后，执行下面的Redis Lua脚本来&lt;strong&gt;释放锁&lt;/strong&gt;：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if redis.call(&amp;quot;get&amp;quot;,KEYS[1]) == ARGV[1] then
    return redis.call(&amp;quot;del&amp;quot;,KEYS[1])
else
    return 0
end复制代码
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这段Lua脚本在执行的时候要把前面的&lt;code&gt;my_random_value&lt;/code&gt;作为&lt;code&gt;ARGV[1]&lt;/code&gt;的值传进去，把&lt;code&gt;resource_name&lt;/code&gt;作为&lt;code&gt;KEYS[1]&lt;/code&gt;的值传进去.&lt;/p&gt;

&lt;p&gt;有几个点要注意下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;锁的过期时间，如果一个客户端获取到锁只有崩溃了，那么其他客户端再也不能获取到这个锁。所以要设置这个有效时间。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;设置一个随机字符串 my_random_value很有必要，这保证一个客户端释放的锁是自己持有的那个锁。假如获取锁时&lt;code&gt;SET&lt;/code&gt;的不是一个随机字符串，而是一个固定值，那么可能会发生下面的执行序列：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;客户端1获取锁成功。&lt;/li&gt;
&lt;li&gt;客户端1在某个操作上阻塞了很长时间。&lt;/li&gt;
&lt;li&gt;过期时间到了，锁自动释放了。&lt;/li&gt;
&lt;li&gt;客户端2获取到了对应同一个资源的锁。&lt;/li&gt;
&lt;li&gt;客户端1从阻塞中恢复过来，释放掉了客户端2持有的锁。&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;之后，客户端2在访问共享资源的时候，就没有锁为它提供保护了。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;释放锁的过程：释放锁的过程必须使用lua脚本或（multi）来实现。释放锁其实包含三步操作：&amp;rsquo;GET&amp;rsquo;、判断和&amp;rsquo;DEL&amp;rsquo;，用Lua脚本来实现能保证这三步的原子性。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;redlock&#34;&gt;redlock&lt;/h3&gt;

&lt;p&gt;我们想象一个这样的场景当机器A申请到一把锁之后，如果Redis主宕机了，这个时候从机并没有同步到这一把锁，那么机器B再次申请的时候就会再次申请到这把锁，为了解决这个问题Redis作者提出了RedLock红锁的算法,在Redission中也对RedLock进行了实现。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//三个redis的集群
Rlock lock1 = redissonInstance1.getLock(&amp;quot;lock1&amp;quot;);
Rlock lock2 = redissonInstance2.getLock(&amp;quot;lock2&amp;quot;);
Rlock lock3 = redissonInstance3.getLock(&amp;quot;lock3&amp;quot;);

RedissonRedLock lock = new REdissonRedLock(lock1,lock2,lock3);
lock.lock();
  ...
lock.unlock();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过上面的代码，我们需要实现多个Redis集群，然后进行红锁的加锁，解锁。具体的步骤如下:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;首先生成多个Redis集群的Rlock，并将其构造成RedLock。&lt;/li&gt;
&lt;li&gt;依次循环对三个集群进行加锁，加锁的过程和5.2里面一致。&lt;/li&gt;
&lt;li&gt;如果循环加锁的过程中加锁失败，那么需要判断加锁失败的次数是否超出了最大值，这里的最大值是根据集群的个数，比如三个那么只允许失败一个，五个的话只允许失败两个，要保证多数成功。&lt;/li&gt;
&lt;li&gt;加锁的过程中需要判断是否加锁超时，有可能我们设置加锁只能用3ms，第一个集群加锁已经消耗了3ms了。那么也算加锁失败。&lt;/li&gt;
&lt;li&gt;3，4步里面加锁失败的话，那么就会进行解锁操作，解锁会对所有的集群在请求一次解锁。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;可以看见RedLock基本原理是利用多个Redis集群，用&lt;strong&gt;多数&lt;/strong&gt;的集群加锁成功，减少Redis某个集群出故障，造成分布式锁出现问题的概率。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;redis锁小结&lt;/strong&gt;：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;优点:对于Redis实现简单，性能对比ZK和Mysql较好。如果不需要特别复杂的要求，那么自己就可以利用setNx进行实现，如果自己需要复杂的需求的话那么可以利用或者借鉴Redission。对于一些要求比较严格的场景来说的话可以使用RedLock。&lt;/li&gt;
&lt;li&gt;缺点:需要维护Redis集群，如果要实现RedLock那么需要维护更多的集群。&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Redis持久化与同步</title>
      <link>https://kphn.github.io/post/2019/redis%E6%8C%81%E4%B9%85%E5%8C%96%E4%B8%8E%E5%90%8C%E6%AD%A5/</link>
      <pubDate>Tue, 28 May 2019 15:34:09 +0800</pubDate>
      
      <guid>https://kphn.github.io/post/2019/redis%E6%8C%81%E4%B9%85%E5%8C%96%E4%B8%8E%E5%90%8C%E6%AD%A5/</guid>
      
        <description>

&lt;h2 id=&#34;持久化&#34;&gt;持久化&lt;/h2&gt;

&lt;p&gt;redis 持久化有两种方式，RDB与AOF。&lt;/p&gt;

&lt;h3 id=&#34;rdb&#34;&gt;RDB&lt;/h3&gt;

&lt;p&gt;优点:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;利于备份&lt;/li&gt;
&lt;li&gt;适用于故障恢复&lt;/li&gt;
&lt;li&gt;比AOF重启更快
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;缺点:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;备份会造成更大的数据损失&lt;/li&gt;
&lt;li&gt;需要使用fork子进程来持久化数据到盘上，如果数据量较大，会造成同步期间短暂的停止服务。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;aof&#34;&gt;AOF&lt;/h3&gt;

&lt;p&gt;优点:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;持久化做的更好，可以选择三种同步策略，不同步、一秒同步一次，每次更新同步一次。默认策略是每秒同步一次，而且性能也很优秀，但是仍会造成一秒的数据损失。&lt;/li&gt;
&lt;li&gt;AOF 的日志是append only log, 没有seek操作，在电力故障的时候不会发生文件损坏。就算最后一条命令只写入一般，redis检查工具也可以对其进行修复。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;缺点:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;AOF文件通常比RDB文件大的多&lt;/li&gt;
&lt;li&gt;就算AOF每秒同步一次写，其性能损耗仍然不小。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;日志重写:&lt;/p&gt;

&lt;p&gt;​   在日志量较大的情况下，AOF数据载入的性能较低，使用日志重写，可以将历史上对一条key的所有操作替换成一条操作。&lt;/p&gt;

&lt;p&gt;redis数据库在进行AOF日志重写期间仍可以继续处理命令请求，而新的命令可能对现有的数据进行修改，这可能造成当前数据库的数据和重写后的数据不一致。为解决这个问题，redis增加了一个AOF重写缓存，redis服务器在执行完写命令之后，会同时将这个写命令追加到AOF缓冲区和AOF重写缓冲区。&lt;/p&gt;

&lt;h2 id=&#34;同步&#34;&gt;同步&lt;/h2&gt;

&lt;h3 id=&#34;旧版复制&#34;&gt;旧版复制&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;同步sync :将从数据库中的数据库状态更新至主服务器当前所处的数据库状态。&lt;/li&gt;
&lt;li&gt;命令传播：主库出现写命令导致主从不一致时，发送写命令给从库&lt;/li&gt;
&lt;li&gt;如果网络断开一段时间，需要重新同步，库较大时会导致耗时较长
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;新版复制&#34;&gt;新版复制&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;psync:分为完整重同步和部分重同步&lt;/li&gt;
&lt;li&gt;完整重同步跟同步sync一样&lt;/li&gt;
&lt;li&gt;部分重同步，主服务器和从服务器各维护一个offset，根据偏移量，从服务器与主服务器重连之后不必&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;cluster&#34;&gt;cluster&lt;/h2&gt;
</description>
      
    </item>
    
    <item>
      <title>网络编程</title>
      <link>https://kphn.github.io/post/2019/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/</link>
      <pubDate>Fri, 03 May 2019 15:51:09 +0800</pubDate>
      
      <guid>https://kphn.github.io/post/2019/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/</guid>
      
        <description>

&lt;h2 id=&#34;客户端-服务器编程模型&#34;&gt;客户端-服务器编程模型&lt;/h2&gt;

&lt;p&gt;每个网络应用都是基于&lt;code&gt;客户端-服务器模型&lt;/code&gt;的。基于这个模型，一个应用是由一个服务器进程和一个或多个客户端进程组成。服务器管理者某种资源，并利用这种资源为其他客户端提供服务。
常见的类型有：&lt;strong&gt;web服务器&lt;/strong&gt;，&lt;strong&gt;FTP服务器&lt;/strong&gt;，&lt;strong&gt;电子邮件服务器&lt;/strong&gt;等。&lt;/p&gt;

&lt;h2 id=&#34;套接字编程&#34;&gt;套接字编程&lt;/h2&gt;

&lt;p&gt;套接字接口流程图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kphn.github.io/image/套接字接口.svg&#34; alt=&#34;socket&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;套接字函数&#34;&gt;套接字函数&lt;/h3&gt;

&lt;p&gt;​   &lt;code&gt;int socket(int domain,int type,int protocol)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;如果想要使套接字成为连接的一个端点，使用 &lt;code&gt;clinetfd = Socket(AF_INET,SOCK_STREAM,0)&lt;/code&gt;,AF_INET代表正在使用32位IP地址，而SOCK_STREAM表示这个套接字是连接的一个端点。socket返回的clientfd描述符仅是部分打开的，还不能用于读写。&lt;/p&gt;

&lt;h3 id=&#34;connect函数&#34;&gt;connect函数&lt;/h3&gt;

&lt;p&gt;客户端通过调用connect函数来建立和服务器的连接。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;int connect(int clientfd,const struct sockaddr *addr,socklen_t addr)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;connect函数试图与套接字地址为addr的服务器建立一个因特网连接，其中addrlen是sizeof（sockaddr_in）。connect函数会阻塞，一直到连接成功建立或者发生错误。如果成功，clientfd描述符现在就可以准备好读写了。&lt;/p&gt;

&lt;h3 id=&#34;bind函数&#34;&gt;bind函数&lt;/h3&gt;

&lt;p&gt;服务器用bind、listen和accept等套接字来和客户端建立连接。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;int bind(int sockfd,const struct sockaddr *addr,socklen_t addrlen&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;bind函数告诉内核将addr中的服务器套接字地址和套接字描述符sockfd联系起来。&lt;/p&gt;

&lt;h3 id=&#34;listen函数&#34;&gt;listen函数&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;int listen(int socktd,int backlog)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;listen函数将sockfd从一个主动套接字转化为一个监听套接字(listening socket),该套接字可以接受来自客户端的连接请求。backlog参数暗示了内核在开始拒绝连接请求之前，队列中要排队的未完成的连接请求的数量。&lt;/p&gt;

&lt;h3 id=&#34;accept函数&#34;&gt;accept函数&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;int accept(int listenfd,struct sockaddr *addr,int *addrlen)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;accept函数等待来自客户端的请求连接到达侦听描述符listenfd，然后在addr中填写客户端的套接字地址，并返回一个*已连接描述符*，这个描述符可被用来利用Unix I/O函数与客户端通信。&lt;/p&gt;

&lt;p&gt;监听描述符vs已连接描述符：监听描述符是作为客户端连接请求中的一个端点。它通常被创建一次，并存在于服务器的整个生命周期。已连接描述符是客户端和服务器之间已经建立起来的一个端点。服务器每次接受连接请求时都会创建一次，它只存在服务器为一个客户端服务的过程中。
&lt;img src=&#34;https://kphn.github.io/image/connfd.png&#34; alt=&#34;socket&#34; /&gt;&lt;/p&gt;

&lt;p&gt;套接字接口区分监听描述符和已连接描述符的一个重要的原因就是：使用连接描述符可以建立并发服务器，它能够同时处理许多客户端连接。例如：每次一个连接请求到达监听描述符时，可以派生出一个新的进程，它通过已连接描述符和客户端通信。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;//简单的单连接无并发的程序
void echo(int connfd);
int main(int argc,char **argv)
{
  int listenfd,connfd;
  socklen_t clientfd;
  struct sockaddr_storage clientaddr;
  char client_hostname[MAXLINE],client_port[MAXLINE];
  
  if (argc!=2){
    exit(0);
  }
  
  listenfd = Open_listenfd(argv[1]);
  while(1){
    clientlen = sizeof(struct sockaddr_storage);
    connfd = Accept(listenfd,(SA *)&amp;amp;clientaddr, &amp;amp;clientlen);
    echo(connfd);
    Close(connfd);
  }
  exit(0);
}
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>Go临时对象池pool原理解析</title>
      <link>https://kphn.github.io/post/2019/go%E4%B8%B4%E6%97%B6%E5%AF%B9%E8%B1%A1%E6%B1%A0pool%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Fri, 12 Apr 2019 20:07:58 +0800</pubDate>
      
      <guid>https://kphn.github.io/post/2019/go%E4%B8%B4%E6%97%B6%E5%AF%B9%E8%B1%A1%E6%B1%A0pool%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/</guid>
      
        <description>

&lt;h2 id=&#34;临时对象池是啥&#34;&gt;临时对象池是啥&lt;/h2&gt;

&lt;p&gt;查看&lt;code&gt;sync.Pool&lt;/code&gt;中的注释来了解&lt;code&gt;pool&lt;/code&gt;的基本用法。主要有以下几点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;pool是一个可以存储和取出临时对象的&lt;strong&gt;&lt;em&gt;临时对象&lt;/em&gt;&lt;/strong&gt;池。&lt;/li&gt;
&lt;li&gt;池中的对象会在没有通知的情况下自动删除，如果一个对象池持有某个对象的唯一引用，那么该对象很有可能被回收。&lt;/li&gt;
&lt;li&gt;pool是多goroutine并发安全的。&lt;/li&gt;
&lt;li&gt;pool的目的是缓存已经分配但之后才回用到的对象，来减轻GC的压力。使用pool可以高效的构建线程安全的&lt;code&gt;free list&lt;/code&gt;,但是其并不适用于所有场景的&lt;code&gt;free list&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;一个适当的适用场景是：管理一个包内的多个独立运行的线程之间静默共享一组临时元素。pool提供了在多个client之间共享临时元素的机制。&lt;/li&gt;
&lt;li&gt;在fmt包中有一个适用Pool的例子，其维持了一个动态大小的临时输出buffer。&lt;/li&gt;
&lt;li&gt;Pool不适合存储在短生命周期的对象，这种场景下的缓存效果不大。&lt;/li&gt;
&lt;li&gt;一旦一个pool使用之后，便不能再被复制。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code&gt;pool&lt;/code&gt;的结构体定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Pool struct {
	noCopy noCopy

	local     unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal
	localSize uintptr        // size of the local array

	// New optionally specifies a function to generate
	// a value when Get would otherwise return nil.
	// It may not be changed concurrently with calls to Get.
	New func() interface{}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用pool对象的时候，需要传入New方法，来创建自己需要的对象（Get方法拿不到对象的时候，会调用New方法）。&lt;/p&gt;

&lt;p&gt;Pool 中有两个定义的公共方法，分别是 Put - 向池中添加元素；Get - 从池中获取元素，如果没有，则调用 New 生成元素，如果 New 未设置，则返回 nil。&lt;/p&gt;

&lt;h2 id=&#34;使用的基本原理&#34;&gt;使用的基本原理&lt;/h2&gt;

&lt;h3 id=&#34;get&#34;&gt;Get&lt;/h3&gt;

&lt;p&gt;Pool会为每个P维护一个本地池，P的本地池分为私有对象private 和 共享池 shared。私有对象的元数据只能本地P使用，共享池中的shared中的元素可能会被其他P*偷走*。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Local per-P Pool appendix.
type poolLocalInternal struct {
  //P私有元素,获取private不需要加锁
	private interface{}   // Can be used only by the respective P.
  //各个P共享元素池，获取shared需要加锁
	shared  []interface{} // Can be used by any P.
	Mutex                 // Protects shared.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Get会优先查找本地private，再查找本地shared，最后再去其他P的shared去查找。如果都查不到则会调用New函数来获取新元素。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;

func (p *Pool) Get() interface{} {
	if race.Enabled {
		race.Disable()
	}
	l := p.pin()
  //先取private
	x := l.private
	l.private = nil
	runtime_procUnpin()
	if x == nil {
		l.Lock()
		last := len(l.shared) - 1
		if last &amp;gt;= 0 {
      //加锁取shared
			x = l.shared[last]
			l.shared = l.shared[:last]
		}
		l.Unlock()
		if x == nil {
      //去取其他P的对象池数据
			x = p.getSlow()
		}
	}
	if race.Enabled {
		race.Enable()
		if x != nil {
			race.Acquire(poolRaceAddr(x))
		}
	}
  //都不存在则创建新对象，此时pool持有的对象未必为空，其他p可能是有私有数据的
	if x == nil &amp;amp;&amp;amp; p.New != nil {
		x = p.New()
	}
	return x
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;getslow&#34;&gt;getSlow&lt;/h3&gt;

&lt;p&gt;getSlow 会从其他的P中的shared获取可用元素：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (p *Pool) getSlow() (x interface{}) {
	// See the comment in pin regarding ordering of the loads.
	size := atomic.LoadUintptr(&amp;amp;p.localSize) // load-acquire
	local := p.local                         // load-consume
	// Try to steal one element from other procs.
	pid := runtime_procPin()
	runtime_procUnpin()
	for i := 0; i &amp;lt; int(size); i++ {
		l := indexLocal(local, (pid+i+1)%int(size))
    //对应的pool需要加上锁
		l.Lock()
		last := len(l.shared) - 1
		if last &amp;gt;= 0 {
			x = l.shared[last]
			l.shared = l.shared[:last]
			l.Unlock()
			break
		}
		l.Unlock()
	}
	return x
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;put&#34;&gt;Put&lt;/h3&gt;

&lt;p&gt;Put优先把数据放到private对象中，如果private对象不为空，则放入shared池中。但是在放入池中时，会有1/4的几率把池数据丢掉。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Put adds x to the pool.
func (p *Pool) Put(x interface{}) {
	if x == nil {
		return
	}
	if race.Enabled {
    //随机丢掉数据
		if fastrand()%4 == 0 {
			// Randomly drop x on floor.
			return
		}
		race.ReleaseMerge(poolRaceAddr(x))
		race.Disable()
	}
	l := p.pin()
  //优先放入private对象中
	if l.private == nil {
		l.private = x
		x = nil
	}
	runtime_procUnpin()
	if x != nil {
		l.Lock()
    //其次放入shared池中
		l.shared = append(l.shared, x)
		l.Unlock()
	}
	if race.Enabled {
		race.Enable()
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;poolcleanup&#34;&gt;poolCleanup&lt;/h3&gt;

&lt;p&gt;在STW阶段，垃圾回收时，poolCleanup就会被调用。如果此时pool.shared被一个goroutine占用，那么整个Pool都会被保留下来，下次清理时内存占用差不多会翻一倍。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func poolCleanup() {
	// This function is called with the world stopped, at the beginning of a garbage collection.
	// It must not allocate and probably should not call any runtime functions.
	// Defensively zero out everything, 2 reasons:
	// 1. To prevent false retention of whole Pools.
	// 2. If GC happens while a goroutine works with l.shared in Put/Get,
	//    it will retain whole Pool. So next cycle memory consumption would be doubled.
	for i, p := range allPools {
		allPools[i] = nil
		for i := 0; i &amp;lt; int(p.localSize); i++ {
			l := indexLocal(p.local, i)
			l.private = nil
			for j := range l.shared {
				l.shared[j] = nil
			}
			l.shared = nil
		}
		p.local = nil
		p.localSize = 0
	}
	allPools = []*Pool{}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;使用示例&#34;&gt;使用示例&lt;/h2&gt;

&lt;p&gt;fmt中的printer pool&lt;/p&gt;

&lt;p&gt;printer与其的临时对象池,newPrinter从对象池中获取printer，free将对象放入对象池中，这样就避免了每次都重新生成打印对象，节省了对象生成时间。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// pp is used to store a printer&#39;s state and is reused with sync.Pool to avoid allocations.
type pp struct {
	buf buffer

	// arg holds the current item, as an interface{}.
	arg interface{}

	// value is used instead of arg for reflect values.
	value reflect.Value

	// fmt is used to format basic items such as integers or strings.
	fmt fmt

	// reordered records whether the format string used argument reordering.
	reordered bool
	// goodArgNum records whether the most recent reordering directive was valid.
	goodArgNum bool
	// panicking is set by catchPanic to avoid infinite panic, recover, panic, ... recursion.
	panicking bool
	// erroring is set when printing an error string to guard against calling handleMethods.
	erroring bool
}

var ppFree = sync.Pool{
	New: func() interface{} { return new(pp) },
}

// newPrinter allocates a new pp struct or grabs a cached one.
func newPrinter() *pp {
	p := ppFree.Get().(*pp)
	p.panicking = false
	p.erroring = false
	p.fmt.init(&amp;amp;p.buf)
	return p
}

// free saves used pp structs in ppFree; avoids an allocation per invocation.
func (p *pp) free() {
	// Proper usage of a sync.Pool requires each entry to have approximately
	// the same memory cost. To obtain this property when the stored type
	// contains a variably-sized buffer, we add a hard limit on the maximum buffer
	// to place back in the pool.
	//
	// See https://golang.org/issue/23199
	if cap(p.buf) &amp;gt; 64&amp;lt;&amp;lt;10 {
		return
	}

	p.buf = p.buf[:0]
	p.arg = nil
	p.value = reflect.Value{}
	ppFree.Put(p)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;源码解析&#34;&gt;源码解析&lt;/h2&gt;
</description>
      
    </item>
    
    <item>
      <title>Go Interface 原理解析</title>
      <link>https://kphn.github.io/post/2019/go-interface-%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Wed, 13 Mar 2019 21:46:30 +0800</pubDate>
      
      <guid>https://kphn.github.io/post/2019/go-interface-%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/</guid>
      
        <description>

&lt;h2 id=&#34;概述&#34;&gt;概述&lt;/h2&gt;

&lt;p&gt;在Go中的，interface是一个非常重要的概念，一般情况下会有两种用法，一种&lt;strong&gt;&lt;em&gt;类似&lt;/em&gt;&lt;/strong&gt;于Java语言的接口的概念，作为Go语言中的一组方法的定义；一种&lt;strong&gt;&lt;em&gt;类似&lt;/em&gt;&lt;/strong&gt;于c 中的&lt;code&gt;void *&lt;/code&gt;的概念，是Go中的抽象类型。&lt;/p&gt;

&lt;h3 id=&#34;方法&#34;&gt;方法&lt;/h3&gt;

&lt;p&gt;比如经常使用的Context类型，只定义了其方法的集合，具体的类型可以有不同的实现方式，传输过程中可以不传递其实现类型，而是直接传递context即可。这样就隐藏了其具体实现。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Context interface {
	Deadline() (deadline time.Time, ok bool)
	Done() &amp;lt;-chan struct{}
	Err() error
	Value(key interface{}) interface{}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不同于其他语言的接口，go语言接口的实现是 &lt;strong&gt;&lt;em&gt;隐式的&lt;/em&gt;&lt;/strong&gt; 。我们不需要像Java那样显式的&lt;code&gt;implement interface&lt;/code&gt;。在golang中 我们只需要给类型定义好接口中的几个方法，那么该类型就自动实现了该接口。&lt;/p&gt;

&lt;p&gt;Go语言会在编译器对代码进行类型检查，如下面代码所示，共触发了三次类型检查:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将 &lt;code&gt;*RPCError&lt;/code&gt; 类型的变量赋值给 &lt;code&gt;error&lt;/code&gt; 类型的变量 &lt;code&gt;rpcErr&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;将 &lt;code&gt;*RPCError&lt;/code&gt; 类型的变量 &lt;code&gt;rpcErr&lt;/code&gt; 传递给签名中参数类型为 &lt;code&gt;error&lt;/code&gt; 的 &lt;code&gt;AsErr&lt;/code&gt; 函数；&lt;/li&gt;

&lt;li&gt;&lt;p&gt;将 &lt;code&gt;*RPCError&lt;/code&gt; 类型的变量从函数签名的返回值类型为 &lt;code&gt;error&lt;/code&gt; 的 &lt;code&gt;NewRPCError&lt;/code&gt; 函数中返回；&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func main() {
var rpcErr error = NewRPCError(400, &amp;quot;unknown err&amp;quot;) // typecheck1
err := AsErr(rpcErr) // typecheck2
println(err) 
}

func NewRPCError(code int64, msg string) error {
return &amp;amp;RPCError{ // typecheck3
    Code:    code,
    Message: msg,
}
}

func AsErr(err error) error {
return err
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;从编译器类型检查的过程来看，编译器仅在需要时才会对类型进行检查，类型实现接口时也只需要隐式的实现所有接口中的方法即可。&lt;/p&gt;

&lt;h3 id=&#34;类型&#34;&gt;类型&lt;/h3&gt;

&lt;p&gt;不带有任何方法的&lt;code&gt;interface{}&lt;/code&gt;类型，使用起来像c中的空指针。不过不同的地方是，&lt;code&gt;interface{}&lt;/code&gt;类型不代表任意类型，&lt;code&gt;interface{}&lt;/code&gt;类型的变量在运行期间的类型只是&lt;code&gt;interface{}&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func Print(v interface{}){
  println(v)
}

Print(Struct{a int}{a:1})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上述Print函数并不能接收任意类型的阐述，只是在调用Print函数时，将参数转换成了&lt;code&gt;interface{}&lt;/code&gt;类型。&lt;/p&gt;

&lt;p&gt;如果需要将&lt;code&gt;interface{}&lt;/code&gt;类型重新转化为其实际类型，需要进行类型断言。&lt;/p&gt;

&lt;p&gt;在Go语言中的源码中，将接口实现表示成了 &lt;code&gt;iface&lt;/code&gt;结构体，将 不包含任何方法的抽象类型表示为&lt;code&gt;eface&lt;/code&gt;结构体。虽然两种类型都使用了&lt;code&gt;interface&lt;/code&gt;进行声明，但是后者由于在Go语言中非常常见，所以在实现时也将它实现成了一种特殊的类型。&lt;/p&gt;

&lt;h3 id=&#34;指针与接口&#34;&gt;指针与接口&lt;/h3&gt;

&lt;p&gt;Go语言是一个有指针类型的语言，接口在定义一组方法时，并没有对实现的接收者做限制，所以可以在一个类型上看到两种不同的实现方式。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;//方式1
type Plane interface{
  Fly()
}

type Helicopter struct{}

func (h *Helicopter)Fly{
  fmt.Println(&amp;quot;helicopter flying&amp;quot;)
}

//方式2
type Plane interface{
  Fly()
}

type Helicopter struct{}

func (h Helicopter)Fly{
  fmt.Println(&amp;quot;helicopter flying&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;理论上，调用者和接收者各有两种类型，一共四种组合。而实际上，方法集规范只包括三种方式，如下表：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Values&lt;/th&gt;
&lt;th&gt;Methods Receivers&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;T&lt;/td&gt;
&lt;td&gt;(t T)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;*T&lt;/td&gt;
&lt;td&gt;(t T) and (t *T)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;有一种情况会编译不通过。就是方法接收者是指针类型，而实际调用者是结构体。&lt;/p&gt;

&lt;p&gt;因为在实际调用者是结构体时，并不是总能获取到结构体的指针的。而反过来，指针总是能获取到其指向的实际结构体，那么指针自然能调用接收器为结构体的方法了。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;因为不能总是获取到一个值的地址，所以指针结构体的方法不能由结构体来调用。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import &amp;quot;fmt&amp;quot;

type myStruct int

func main() {
	fmt.Printf(&amp;quot;%p\n&amp;quot;, &amp;amp;myStruct(1))        //can&#39;t take the address of myStruct(1)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;nil-non-nil&#34;&gt;nil &amp;amp;&amp;amp; non-nil&lt;/h3&gt;

&lt;p&gt;我们可以再通过一个例子理解&lt;strong&gt;『Go 语言的接口类型不是任意类型』&lt;/strong&gt;这一句话，下面的代码在 &lt;code&gt;main&lt;/code&gt;函数中初始化了一个 &lt;code&gt;*TestStruct&lt;/code&gt; 结构体指针，由于指针的零值是 &lt;code&gt;nil&lt;/code&gt;，所以变量 &lt;code&gt;s&lt;/code&gt; 在初始化之后也是 &lt;code&gt;nil&lt;/code&gt;：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import &amp;quot;fmt&amp;quot;

type TestStruct struct{}

func NilOrNot(v interface{}) {
	if v == nil {
		println(&amp;quot;nil&amp;quot;)
	} else {
		println(&amp;quot;non-nil&amp;quot;)
	}
}

func main() {
	var s *TestStruct
	if s == nil {
		fmt.Println(&amp;quot;nil&amp;quot;)
	} else {
		fmt.Println(&amp;quot;non nil&amp;quot;)
	}
	NilOrNot(s)
}


$ go run main.go
nil
non-nil
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;但是当我们将 &lt;code&gt;s&lt;/code&gt; 变量传入 &lt;code&gt;NilOrNot&lt;/code&gt; 时，该方法却打印出了 &lt;code&gt;non-nil&lt;/code&gt; 字符串，这主要是因为调用 &lt;code&gt;NilOrNot&lt;/code&gt; 函数时其实&lt;strong&gt;会发生隐式的类型转换&lt;/strong&gt;，变量 &lt;code&gt;nil&lt;/code&gt; 会被转换成 &lt;code&gt;interface{}&lt;/code&gt; 类型，&lt;code&gt;interface{}&lt;/code&gt; 类型是一个结构体，它除了包含 &lt;code&gt;nil&lt;/code&gt; 变量之外还包含变量的类型信息，也就是 &lt;code&gt;TestStruct&lt;/code&gt;，所以在这里会打印出 &lt;code&gt;nil&lt;/code&gt; &lt;code&gt;non-nil&lt;/code&gt;，在转换为接口之前，变量s确实为nil，但是转化为&lt;code&gt;interface&lt;/code&gt;之后就不再是nil了。&lt;/p&gt;

&lt;h3 id=&#34;类型断言&#34;&gt;类型断言&lt;/h3&gt;

&lt;p&gt;类型断言可以看成一系列类型转换，对每一个swtich case而言，试图转换value的类型。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Stringer interface {
    String() string
}

var value interface{} // Value provided by caller.
switch str := value.(type) {
case string:
    return str
case Stringer:
    return str.String()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用类型转换，等价于如上流程的代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;if str, ok := value.(string); ok {
    return str
} else if str, ok := value.(Stringer); ok {
    return str.String()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进行类型转换时，&lt;code&gt;str,ok := value.(string)&lt;/code&gt;这种方式，可以通过ok来判断value是否转换成功，如果转换不成功，那么str也会变成转换之后类型的&lt;code&gt;零值&lt;/code&gt;。当然，也有一种写法 &lt;code&gt;str := value.(string)&lt;/code&gt;这种方式直接进行类型转换，而一旦转换不成功，那么代码就会直接panic。&lt;/p&gt;

&lt;h2 id=&#34;why-interface&#34;&gt;why interface&lt;/h2&gt;

&lt;h3 id=&#34;泛型&#34;&gt;泛型&lt;/h3&gt;

&lt;p&gt;使用 &lt;code&gt;interfae&lt;/code&gt;可以实现范型编程，比如我们现在要写一个泛型算法，形参定义采用 interface 就可以了，以标准库的 sort 为例。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Interface interface {
    Len() int
    Less(i, j int) bool
    Swap(i, j int)
}

func Sort(data Interface) {
    n := data.Len()
    maxDepth := 0
    for i := n; i &amp;gt; 0; i &amp;gt;&amp;gt;= 1 {
        maxDepth++
    }
    maxDepth *= 2
    quickSort(data, 0, n, maxDepth)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sort 函数的形参是一个 interface，包含了三个方法：&lt;code&gt;Len()&lt;/code&gt;，&lt;code&gt;Less(i,j int)&lt;/code&gt;，&lt;code&gt;Swap(i, j int)&lt;/code&gt;。使用的时候不管数组的元素类型是什么类型（int, float, string…），只要我们实现了这三个方法就可以使用 Sort 函数，这样就实现了“泛型编程”。有一点比较麻烦的是，我们需要将数组自定义一下。&lt;/p&gt;

&lt;h3 id=&#34;隐藏具体实现&#34;&gt;隐藏具体实现&lt;/h3&gt;

&lt;p&gt;隐藏具体实现，这个很好理解。比如我设计一个函数给你返回一个 &lt;code&gt;interface&lt;/code&gt;，那么你只能通过 &lt;code&gt;interface&lt;/code&gt; 里面的方法来做一些操作，但是内部的具体实现是完全不知道的。如 下图演示的&lt;code&gt;context&lt;/code&gt; 接口：尽管内部实现上下面三个函数返回的具体 struct （都实现了 Context interface）不同，但是对于使用者来说是完全无感知的。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func WithCancel(parent Context) (ctx Context, cancel CancelFunc)    //返回 cancelCtx
func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc) //返回 timerCtx
func WithValue(parent Context, key, val interface{}) Context    //返回 valueCtx
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;providing-interception-points&#34;&gt;providing interception points&lt;/h3&gt;

&lt;p&gt;这里应该是 wrapper 或者装饰器，文章末尾视频中Francesc给出了一个例子如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type header struct {
    rt  http.RoundTripper
    v   map[string]string
}

func (h header) RoundTrip(r *http.Request) *http.Response {
    for k, v := range h.v {
        r.Header.Set(k,v)
    }
    return h.rt.RoundTrip(r)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过 interface，我们可以通过类似这种方式实现 dynamic dispatch。&lt;/p&gt;

&lt;p&gt;另外golang中一个重要的原则就是,返回具体的类型，而接收参数的时候接收 接口类型，这样可以提升程序的健壮性，而且可以使得方法很容易进行测试：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Return &lt;strong&gt;concrete types&lt;/strong&gt;, receive &lt;strong&gt;interfaces&lt;/strong&gt; as parameter. — Robustness Principle applied to Go&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;非侵入式&#34;&gt;非侵入式&lt;/h3&gt;

&lt;p&gt;上面提过，golang的接口是隐式的实现的，在编译期一个结构体作为一个接口传递，会检测该结构体是否实现了接口的所有方法。一个结构体可以实现多个接口，只要其实现了这几个接口的方法。假设接口的方法个数为m，结构体实现的方法的个数为n，检查结构体是否实现接口的时间复杂度为 O( m*n )。在将方法进行排序之后，时间复杂度可以将为O( m + n )。&lt;/p&gt;

&lt;p&gt;同时不同于Java中实现一个接口需要显示的implement 一个接口，golang中可以减少对包的依赖。但是这样也会带来一个新的问题：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;性能下降，使用 &lt;code&gt;interface&lt;/code&gt;作为函数参数，runtime的时候会动态的确定行为。而使用struct作为参数的话，编译期间就可以确定了。&lt;/li&gt;
&lt;li&gt;不知道 struct 实现了哪些interface。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;tip：使用规范：可以实现多个接口，编译时检测vs运行时检测&lt;/p&gt;

&lt;p&gt;如果没有额外的导出函数，实现接口的方法可以用接口来传递（方便替换，open - close原则）&lt;/p&gt;

&lt;p&gt;返回具体值，接收方接收interface，但是如果不想让接收方看到具体细节，也可以直接返回interface。&lt;/p&gt;

&lt;h2 id=&#34;内部实现原理&#34;&gt;内部实现原理&lt;/h2&gt;

&lt;p&gt;上面提到： Go 语言中其实有两种略微不同的接口，其中一种是带有一组方法的接口，另一种是不带有任何方法的 &lt;code&gt;interface{}&lt;/code&gt; 类型。这两种不同的接口，在go语言的源代码中也有着不同的定义：第一种接口表示为 &lt;code&gt;iface&lt;/code&gt;， 而第二种表示成 &lt;code&gt;eface&lt;/code&gt;结构体。&lt;/p&gt;

&lt;h3 id=&#34;eface&#34;&gt;eface&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type eface struct { // 16 bytes
    _type *_type
    data  unsafe.Pointer
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由于&lt;code&gt;interface{}&lt;/code&gt;类型不包含任何方法，所以其结构也相对简单，只包含指向底层数据和类型的两个指针，从这里的结构可以推断出，任意的类型都可以转换成&lt;code&gt;interface{}&lt;/code&gt;类型。&lt;/p&gt;

&lt;h3 id=&#34;iface&#34;&gt;iface&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type iface struct { // 16 bytes
    tab  *itab
    data unsafe.Pointer
}

type itab struct { // 32 bytes
    inter *interfacetype
    _type *_type
    hash  uint32 // copy of _type.hash. Used for type switches.
    _     [4]byte
    fun   [1]uintptr // variable sized. fun[0]==0 means _type does not implement inter.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;用于表示接口的 &lt;code&gt;interface&lt;/code&gt;类型的底层数据结构就是 &lt;code&gt;iface&lt;/code&gt; 了。在这个结构体中也有指向原始数据的指针 &lt;code&gt;data&lt;/code&gt;,但是这个结构体中更为重要的其实是 &lt;code&gt;itab&lt;/code&gt;类型的&lt;code&gt;tab&lt;/code&gt;字段。&lt;/p&gt;

&lt;h3 id=&#34;itab&#34;&gt;itab&lt;/h3&gt;

&lt;p&gt;在itab结构中，也包含了 eface 中包含的 _type 结构体，每个 _type 结构体中都包含了类型的大小，对齐以及hash等信息。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;hash&lt;/code&gt; 字段其实是对 &lt;code&gt;_type.hash&lt;/code&gt; 的拷贝，它会在从 &lt;code&gt;interface&lt;/code&gt; 到具体类型的切换时用于&lt;strong&gt;快速判断目标类型和接口中类型是否一致&lt;/strong&gt;；最后的 &lt;code&gt;fun&lt;/code&gt; 数组其实是一个动态大小的数组，如果如果当前数组中内容为空就表示 &lt;code&gt;_type&lt;/code&gt; 没有实现 &lt;code&gt;inter&lt;/code&gt; 接口，虽然这是一个大小固定的数组，但是在使用时会直接通过指针获取其中的数据并不会检查数组的边界，所以该数组中保存的元素数量是不确定的。&lt;code&gt;用户缓存是否实现某个接口&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;itable在头部存储了一些类型相关元数据，之后是一个函数指针的列表。注意itable不是和不动态类型对应的，而是和*interface类型*相对应，只有interface中的方法会存入itable中。&lt;/p&gt;

&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://research.swtch.com/interfaces&#34;&gt;Go Data Structures: Interfaces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://draveness.me/golang/basic/golang-interface.html&#34;&gt;go 接口&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/F4wUrj6pmSI&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
      
    </item>
    
    <item>
      <title>合成复用原则</title>
      <link>https://kphn.github.io/post/2019/%E5%90%88%E6%88%90%E5%A4%8D%E7%94%A8%E5%8E%9F%E5%88%99/</link>
      <pubDate>Thu, 28 Jun 2018 08:41:18 +0800</pubDate>
      
      <guid>https://kphn.github.io/post/2019/%E5%90%88%E6%88%90%E5%A4%8D%E7%94%A8%E5%8E%9F%E5%88%99/</guid>
      
        <description>

&lt;h2 id=&#34;定义&#34;&gt;定义&lt;/h2&gt;

&lt;p&gt;合成复用原则（Composite Reuse Principle，CRP）又叫组合/聚合复用原则（Composition/Aggregate Reuse Principle，CARP）：它要求在软件复用时，要尽量先使用组合或者聚合等关联关系来实现，其次才考虑使用继承关系来实现。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;如果要使用继承关心，必须严格遵循里氏替换原则。&lt;/code&gt;合成复用原则同里氏替换原则是相辅相成的，两者都是开闭原则的具体实现规范。&lt;/p&gt;

&lt;h2 id=&#34;重要性&#34;&gt;重要性&lt;/h2&gt;

&lt;p&gt;通常类的复用分为继承复用和组合复用两种，继承复用虽然有简单和易实现的优点，但也存在以下缺点。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;继承复用&lt;strong&gt;&lt;em&gt;破坏了类的封装性&lt;/em&gt;&lt;/strong&gt;。因为继承会将父类的实现细节暴露给子类，父类对子类是透明的，所以这种复用又称为“白箱”复用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;子类与父类的耦合度高&lt;/strong&gt;。父类的实现的任何改变都会&lt;strong&gt;&lt;em&gt;导致子类的实现发生变化&lt;/em&gt;&lt;/strong&gt;，这不利于类的扩展与维护。&lt;/li&gt;
&lt;li&gt;它限制了复用的灵活性。从父类继承而来的实现是静态的，在&lt;strong&gt;&lt;em&gt;编译时已经定义&lt;/em&gt;&lt;/strong&gt;，所以在运行时不可能发生变化。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;采用组合或聚合复用时，可以将已有对象纳入新对象中，使之成为新对象的一部分，新对象可以调用已有对象的功能，它有以下优点。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;它维持了类的封装性。因为成分对象的内部细节是新对象看不见的，所以这种复用又称为“黑箱”复用。&lt;/li&gt;
&lt;li&gt;新旧类之间的耦合度低。这种复用所需的依赖较少，新对象存取成分对象的唯一方法是通过成分对象的接口。&lt;/li&gt;
&lt;li&gt;复用的灵活性高。这种复用可以在运行时动态进行，新对象可以动态地引用与成分对象类型相同的对象。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;共介绍了7种设计原则，它们分别为&lt;a href=&#34;https://kphn.github.io/post/open-close/&#34;&gt;开闭原则&lt;/a&gt;、&lt;a href=&#34;https://kphn.github.io/post/里氏替换原则&#34;&gt;里氏替换原则&lt;/a&gt;、&lt;a href=&#34;https://kphn.github.io/post/依赖倒置原则/&#34;&gt;依赖倒置原则&lt;/a&gt;、&lt;a href=&#34;https://kphn.github.io/post/单一职责/&#34;&gt;单一职责原则&lt;/a&gt;、&lt;a href=&#34;https://kphn.github.io/post/接口隔离原则&#34;&gt;接口隔离原则&lt;/a&gt;、&lt;a href=&#34;https://kphn.github.io/post/迪米特法则/&#34;&gt;迪米特法则&lt;/a&gt;和本节所介绍的合成复用原则。&lt;/p&gt;

&lt;p&gt;这 7 种设计原则是软件&lt;a href=&#34;https://kphn.github.io/post/设计模式/&#34;&gt;设计模式&lt;/a&gt;必须尽量遵循的原则，各种原则要求的侧重点不同。其中，开闭原则是总纲，它告诉我们要对扩展开放，对修改关闭；里氏替换原则告诉我们不要破坏继承体系；依赖倒置原则告诉我们要面向接口编程；单一职责原则告诉我们实现类要职责单一；接口隔离原则告诉我们在设计接口的时候要精简单一；迪米特法则告诉我们要降低耦合度；合成复用原则告诉我们要优先使用组合或者聚合关系复用，少用继承关系复用。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>迪米特法则</title>
      <link>https://kphn.github.io/post/2019/%E8%BF%AA%E7%B1%B3%E7%89%B9%E6%B3%95%E5%88%99/</link>
      <pubDate>Thu, 28 Jun 2018 08:27:57 +0800</pubDate>
      
      <guid>https://kphn.github.io/post/2019/%E8%BF%AA%E7%B1%B3%E7%89%B9%E6%B3%95%E5%88%99/</guid>
      
        <description>

&lt;h2 id=&#34;定义&#34;&gt;定义&lt;/h2&gt;

&lt;p&gt;迪米特法则（Law of Demeter）：又称最少知识原则（Least Knowledge Principle，LKP），只与你的直接朋友交谈，不跟“陌生人”说话（Talk only to your immediate friends and not to strangers）。其含义是：如果两个软件实体无须直接通信，那么就不应当发生直接的相互调用，可以通过第三方转发该调用。其目的是降低类之间的耦合度，提高模块的相对独立性。&lt;/p&gt;

&lt;p&gt;迪米特法则中的“朋友”是指：当前对象本身、当前对象的成员对象、当前对象所创建的对象、当前对象的方法参数等，这些对象同当前对象存在关联、聚合或组合关系，可以直接访问这些对象的方法。&lt;/p&gt;

&lt;h2 id=&#34;优点&#34;&gt;优点&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;降低了类之间的耦合度，提高了模块的相对独立性。&lt;/li&gt;
&lt;li&gt;由于亲和度降低，从而提高了类的可复用率和系统的扩展性。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;但是，过度使用迪米特法则会使系统产生大量的&lt;strong&gt;中介类(Agent)&lt;/strong&gt;，从而增加系统的复杂性，使模块之间的通信效率降低。所以，在采用迪米特法则时需要反复权衡，确保高内聚和低耦合的同时，保证系统的结构清晰。&lt;/p&gt;

&lt;h2 id=&#34;实现方法&#34;&gt;实现方法&lt;/h2&gt;

&lt;p&gt;从迪米特法则的定义和特点可知，它强调以下两点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;从依赖者的角度来说，只依赖应该依赖的对象。&lt;/li&gt;
&lt;li&gt;从被依赖者的角度说，只暴露应该暴露的方法。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;所以，在运用迪米特法则时要注意以下 6 点。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;在类的划分上，应该创建弱耦合的类。类与类之间的耦合越弱，就越有利于实现可复用的目标。&lt;/li&gt;
&lt;li&gt;在类的结构设计上，尽量降低类成员的访问权限。&lt;/li&gt;
&lt;li&gt;在类的设计上，优先考虑将一个类设置成不变类。&lt;/li&gt;
&lt;li&gt;在对其他类的引用上，将引用其他对象的次数降到最低。&lt;/li&gt;
&lt;li&gt;不暴露类的属性成员，而应该提供相应的访问器（set 和 get 方法）。&lt;/li&gt;
&lt;li&gt;谨慎使用序列化（Serializable）功能。&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>接口隔离原则</title>
      <link>https://kphn.github.io/post/2019/%E6%8E%A5%E5%8F%A3%E9%9A%94%E7%A6%BB%E5%8E%9F%E5%88%99/</link>
      <pubDate>Thu, 28 Jun 2018 08:16:33 +0800</pubDate>
      
      <guid>https://kphn.github.io/post/2019/%E6%8E%A5%E5%8F%A3%E9%9A%94%E7%A6%BB%E5%8E%9F%E5%88%99/</guid>
      
        <description>

&lt;h2 id=&#34;定义&#34;&gt;定义&lt;/h2&gt;

&lt;p&gt;接口隔离原则（Interface Segregation Principle，ISP）要求程序员尽量将臃肿庞大的接口拆分成更小和更具体的接口，让接口中只包含客户感兴趣的方法。定义：客户端不应该被迫依赖于它不适用的方法（Clients should not be forced to depend on methods they do not use）。该原则还有另外一个定义：一个类对另一个类的依赖应该建立在最小的接口上（The dependency of one class to another one should depend on the smallest possible interface）。&lt;/p&gt;

&lt;p&gt;以上两个定义的含义是：要为各个类建立它们需要的专用接口，而不要试图去建立一个很庞大的接口供所有依赖它的类去调用。&lt;/p&gt;

&lt;p&gt;接口隔离原则和单一职责都是为了提高类的内聚性、降低它们之间的耦合性，体现了封装的思想，但两者是不同的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;单一职责原则注重的是职责，而接口隔离原则注重的是对接口依赖的隔离。&lt;/li&gt;
&lt;li&gt;单一职责原则主要是约束类，它针对的是程序中的实现和细节；接口隔离原则主要约束接口，主要针对抽象和程序整体框架的构建。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;优点&#34;&gt;优点&lt;/h2&gt;

&lt;p&gt;接口隔离原则是为了约束接口、降低类对接口的依赖性，遵循接口隔离原则有以下 5 个优点。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将臃肿庞大的接口分解为多个粒度小的接口，可以预防外来变更的扩散，提高系统的灵活性和可维护性。&lt;/li&gt;
&lt;li&gt;接口隔离提高了系统的内聚性，减少了对外交互，降低了系统的耦合性。&lt;/li&gt;
&lt;li&gt;如果接口的粒度大小定义合理，能够保证系统的稳定性；但是，如果定义过小，则会造成接口数量过多，使设计复杂化；如果定义太大，灵活性降低，无法提供定制服务，给整体项目带来无法预料的风险。&lt;/li&gt;
&lt;li&gt;使用多个专门的接口还能够体现对象的层次，因为可以通过接口的继承，实现对总接口的定义。&lt;/li&gt;
&lt;li&gt;能减少项目工程中的代码冗余。过大的大接口里面通常放置许多不用的方法，当实现这个接口的时候，被迫设计冗余的代码。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;实现方法&#34;&gt;实现方法&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;接口尽量小，但是要有限度。一个接口只服务于一个子模块或业务逻辑&lt;/li&gt;
&lt;li&gt;为依赖接口的类定制服务。只提供调用者需要的方法，屏蔽不需要的方法。&lt;/li&gt;
&lt;li&gt;了解环境，拒绝盲从。每个项目或产品都有选定的环境因素，环境不同，接口拆分的标准就不同，深入了解业务逻辑。&lt;/li&gt;
&lt;li&gt;提高内聚，减少对外交互。使接口用最少的方法去完成最多的事情。&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>单一职责原则</title>
      <link>https://kphn.github.io/post/2019/%E5%8D%95%E4%B8%80%E8%81%8C%E8%B4%A3/</link>
      <pubDate>Thu, 28 Jun 2018 08:05:42 +0800</pubDate>
      
      <guid>https://kphn.github.io/post/2019/%E5%8D%95%E4%B8%80%E8%81%8C%E8%B4%A3/</guid>
      
        <description>

&lt;h2 id=&#34;定义&#34;&gt;定义&lt;/h2&gt;

&lt;p&gt;单一职责原则（Single Responsibility Principle，SRP）又称单一功能原则：规定一个类应该且仅有一个引起它变化的原因，否则类应该被拆分。&lt;/p&gt;

&lt;p&gt;该原则提出对象不应该承担太多职责，如果一个对象承担了太多的职责，至少存在以下两个缺点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;一个职责的变化可能会削弱或者抑制这个类实现其他职责的能力；&lt;/li&gt;
&lt;li&gt;当客户端需要该对象的某一个职责时，不得不将其他不需要的职责全部包含进来，从而造成冗余代码或代码的浪费。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;优点&#34;&gt;优点&lt;/h2&gt;

&lt;p&gt;单一职责原则的核心就是&lt;strong&gt;控制类的粒度大小&lt;/strong&gt;、将对象&lt;strong&gt;解耦、提高其内聚性&lt;/strong&gt;。如果遵循单一职责原则将有以下优点。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;降低类的复杂度。一个类只负责一项职责。&lt;/li&gt;
&lt;li&gt;提高类的可读性。&lt;/li&gt;
&lt;li&gt;提高系统的可维护性。&lt;/li&gt;
&lt;li&gt;变更引起的风险降低。当修改一个功能时，可以显著降低对其他功能的影响。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;实现方法&#34;&gt;实现方法&lt;/h2&gt;

&lt;p&gt;单一职责原则是最简单但又比较难运用的原则，需要设计人员发现类的不同职责并将其分离，再封装到不同的类或者模块中。而发现类的多重职责需要设计人员具有较强的分析设计能力和相关重构经验。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>依赖倒置原则</title>
      <link>https://kphn.github.io/post/2019/%E4%BE%9D%E8%B5%96%E5%80%92%E7%BD%AE%E5%8E%9F%E5%88%99/</link>
      <pubDate>Wed, 27 Jun 2018 08:42:55 +0800</pubDate>
      
      <guid>https://kphn.github.io/post/2019/%E4%BE%9D%E8%B5%96%E5%80%92%E7%BD%AE%E5%8E%9F%E5%88%99/</guid>
      
        <description>

&lt;h2 id=&#34;定义&#34;&gt;定义&lt;/h2&gt;

&lt;p&gt;依赖倒置原则（Dependence Inversion Principle，DIP）：高层模块不应该依赖底层模块，两者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象（High level modules shouldnot depend upon low level modules.Both should depend upon abstractions.Abstractions should not depend upon details. Details should depend upon abstractions）。其核心思想是&lt;code&gt;面向接口编程，不要面向实现编程&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;依赖倒置原则是实现开闭原则的重要途径之一，它降低了客户与实现模块之间的耦合。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在软件设计中，细节具有多变性，而抽象层则相对稳定，因此以抽象为基础搭建起来的架构要比以细节搭建起来的架构稳定的多。这里的抽象指的是接口或者抽象类，而细节是指具体的实现类。&lt;/p&gt;

&lt;p&gt;使用接口或者抽象类的目的是制定好规范和契约，而不去涉及任何具体的操作，把展现细节的任务交给它们的实现类去完成。&lt;/p&gt;

&lt;h2 id=&#34;作用&#34;&gt;作用&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;依赖倒置降低了类间的耦合性&lt;/li&gt;
&lt;li&gt;依赖倒置提高了系统的稳定性&lt;/li&gt;
&lt;li&gt;依赖倒置减少并行开发引起的风险&lt;/li&gt;
&lt;li&gt;依赖倒置提高了代码的可读性和可维护性&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;实现方法&#34;&gt;实现方法&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;依赖倒置原则的目的是通过面向接口的编程来降低类间的耦合性&lt;/code&gt;，需要遵循以下几点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;每个类尽量提供接口或抽象类，或者两者都具备&lt;/li&gt;
&lt;li&gt;变量的声明类型尽量是接口或者是抽象类&lt;/li&gt;
&lt;li&gt;任何类都不应该从抽象类派生&lt;/li&gt;

&lt;li&gt;&lt;p&gt;使用继承时尽量遵循里氏替换原则&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package principle;
public class DIPtest
{
public static void main(String[] args)
{
    Customer wang=new Customer();
    System.out.println(&amp;quot;顾客购买以下商品：&amp;quot;); 
    wang.shopping(new ShaoguanShop()); 
    wang.shopping(new WuyuanShop());
}
}
//商店
interface Shop
{
public String sell(); //卖
}
//韶关网店
class ShaoguanShop implements Shop
{
public String sell()
{
    return &amp;quot;韶关土特产：香菇、木耳……&amp;quot;; 
} 
}
//婺源网店
class WuyuanShop implements Shop
{
public String sell()
{
    return &amp;quot;婺源土特产：绿茶、酒糟鱼……&amp;quot;; 
}
} 
//顾客
class Customer
{
public void shopping(Shop shop)
{
    //购物
    System.out.println(shop.sell()); 
}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>开放闭合原则</title>
      <link>https://kphn.github.io/post/2019/open-close/</link>
      <pubDate>Tue, 26 Jun 2018 23:17:56 +0800</pubDate>
      
      <guid>https://kphn.github.io/post/2019/open-close/</guid>
      
        <description>

&lt;h2 id=&#34;开闭原则&#34;&gt;开闭原则&lt;/h2&gt;

&lt;h3 id=&#34;定义&#34;&gt;定义&lt;/h3&gt;

&lt;p&gt;OCP（Open Closed Principle）：软件实体应当对扩展开放，对修改关闭（Software entities should be open for extension，but closed for modification）。&lt;/p&gt;

&lt;p&gt;这里的软件实体包括以下几个部分：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;项目中划分出的模块&lt;/li&gt;
&lt;li&gt;类与接口&lt;/li&gt;
&lt;li&gt;方法&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;开闭原则的含义是：当应用的需求改变时，在不修改软件实体的源代码或者二进制代码的前提下，可以扩展模块的功能，使其满足新的需求。&lt;/p&gt;

&lt;h3 id=&#34;作用与实现方法&#34;&gt;作用与实现方法&lt;/h3&gt;

&lt;p&gt;开闭原则是面向对象程序设计的终极目标，它使软件实体拥有一定的适应性和灵活性的同时具备稳定性和延续性。
可以通过“抽象约束、封装变化”来实现开闭原则，即通过接口或者抽象类为软件实体定义一个相对稳定的抽象层，而将相同的可变因素封装在相同的具体实现类中。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>设计模式</title>
      <link>https://kphn.github.io/post/2019/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</link>
      <pubDate>Tue, 26 Jun 2018 08:25:28 +0800</pubDate>
      
      <guid>https://kphn.github.io/post/2019/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</guid>
      
        <description>

&lt;h2 id=&#34;概述&#34;&gt;概述&lt;/h2&gt;

&lt;p&gt;设计模式是前辈们对于代码开发经验的总结，是解决特定问题的一种固定套路。本质上还是对面向对象设计原则的实际运用，是对类的封装性、继承性和多态性，以及类的关联关系和组合关系的充分理解。设计模式最终要做到的就是&lt;strong&gt;将变化的部分和不变的部分隔离开来&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;设计模式有两个核心理念：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Program to an “interface”,not an &amp;ldquo;implementation&amp;rdquo;

&lt;ol&gt;
&lt;li&gt;使用者不需要知道数据类型，结构，算法的细节&lt;/li&gt;
&lt;li&gt;使用者不需要知道实现细节，只需要知道提供的接口&lt;/li&gt;
&lt;li&gt;利于抽象，封装，动态绑定，多态&lt;/li&gt;
&lt;li&gt;符合面向对象的特质和理念&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Favor &amp;lsquo;object composition&amp;rsquo; over &amp;lsquo;class inheritance&amp;rsquo;&amp;rdquo;

&lt;ol&gt;
&lt;li&gt;继承需要给子类暴漏一些父类的设计和实现细节&lt;/li&gt;
&lt;li&gt;父类实现的改变会造成子类也需要改变&lt;/li&gt;
&lt;li&gt;我们以为继承主要是为了代码重用，但实际上在子类中需要重新实现很多父类的方法&lt;/li&gt;
&lt;li&gt;继承更多的应该是为了多态&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;tips&#34;&gt;TIPS&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;封装变化&lt;/li&gt;
&lt;li&gt;多用组合，少用继承&lt;/li&gt;
&lt;li&gt;针对接口编程，不针对实现编程&lt;/li&gt;
&lt;li&gt;将系统中变化的部分抽离出来封装&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;导航&#34;&gt;导航&lt;/h2&gt;

&lt;p&gt;接下来，我将具体的深入到每个设计模式当中去，去探究其使用场景&lt;/p&gt;

&lt;ol class=&#34;task-list&#34;&gt;
&lt;li&gt;面向对象设计原则

&lt;ol class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;a href=&#34;https://kphn.github.io/post/open-close/&#34;&gt;开放闭合原则&lt;/a&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;a href=&#34;https://kphn.github.io/post/里氏替换原则&#34;&gt;里氏替换原则&lt;/a&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;a href=&#34;https://kphn.github.io/post/依赖倒置原则/&#34;&gt;依赖倒置原则&lt;/a&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;a href=&#34;https://kphn.github.io/post/单一职责/&#34;&gt;单一职责原则&lt;/a&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;a href=&#34;https://kphn.github.io/post/接口隔离原则&#34;&gt;接口隔离原则&lt;/a&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;a href=&#34;https://kphn.github.io/post/迪米特法则/&#34;&gt;迪米特法则&lt;/a&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;a href=&#34;https://kphn.github.io/post/合成复用原则/&#34;&gt;合成复用原则&lt;/a&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;设计模式详解

&lt;ol class=&#34;task-list&#34;&gt;
&lt;li&gt;创建性模式&lt;/li&gt;
&lt;li&gt;结构型模式&lt;/li&gt;
&lt;li&gt;行为型模式

&lt;ol class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; [观察者模式]()&lt;/label&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;参考文档&#34;&gt;参考文档&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://c.biancheng.net/design_pattern/&#34;&gt;Java设计模式：23种设计模式全面解析（超级详细）&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>部署ngrok</title>
      <link>https://kphn.github.io/post/2019/%E9%83%A8%E7%BD%B2ngrok/</link>
      <pubDate>Fri, 30 Jun 2017 15:37:14 +0800</pubDate>
      
      <guid>https://kphn.github.io/post/2019/%E9%83%A8%E7%BD%B2ngrok/</guid>
      
        <description>

&lt;h2 id=&#34;ngrok&#34;&gt;ngrok&lt;/h2&gt;

&lt;p&gt;ngrok可以让本地的web服务或tcp服务和外部建立一个安全的通道，使得外网可以访问本地的计算机服务。不仅可以用来暴露内网的http给外网使用，还可以从外网来ssh到本机开发环境。ngrok可以通过官方的服务来连接，也可以自己来。下面介绍下私有的ngrok服务的搭建工作。&lt;/p&gt;

&lt;h2 id=&#34;准备工作&#34;&gt;准备工作&lt;/h2&gt;

&lt;p&gt;搭建ngrok服务需要一个&lt;strong&gt;外网服务器&lt;/strong&gt;以及一个已经解析到了该机器的&lt;strong&gt;域名&lt;/strong&gt;（假定为test.site）,国内可以在阿里云购买相关服务：&lt;a href=&#34;https://promotion.aliyun.com/ntms/yunparter/invite.html?userCode=mwdh54s4&#34;&gt;阿里云&lt;/a&gt;。注意：下文中用到的所有端口，如果启用了iptables规则，都需要放行，如果在阿里云中，需要设置&lt;strong&gt;安全组规则&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&#34;依赖项&#34;&gt;依赖项&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;ngrok使用go语言开发，所以首先要 安装go语言：&lt;a href=&#34;https://golang.org/doc/install&#34;&gt;https://golang.org/doc/install&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;安装&#34;&gt;安装&lt;/h2&gt;

&lt;p&gt;下载代码：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;git clone &lt;a href=&#34;https://github.com/inconshreveable/ngrok.git&#34;&gt;https://github.com/inconshreveable/ngrok.git&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;生成ssl证书：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;cd ngrok&lt;/p&gt;

&lt;p&gt;NGROK_DOMAIN=&amp;ldquo;test.site&amp;rdquo;&lt;/p&gt;

&lt;p&gt;openssl genrsa -out base.key 2048&lt;/p&gt;

&lt;p&gt;openssl req -new -x509 -nodes -key base.key -days 10000 -subj &amp;ldquo;/CN=$NGROK_DOMAIN&amp;rdquo; -out base.pem&lt;/p&gt;

&lt;p&gt;openssl genrsa -out server.key 2048&lt;/p&gt;

&lt;p&gt;openssl req -new -key server.key -subj &amp;ldquo;/CN=$NGROK_DOMAIN&amp;rdquo; -out server.csr&lt;/p&gt;

&lt;p&gt;openssl x509 -req -in server.csr -CA base.pem -CAkey base.key -CAcreateserial -days 10000 -out server.crt&lt;/p&gt;

&lt;p&gt;cp base.pem assets/client/tls/ngrokroot.crt&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;编译：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;sudo make release-server release-client&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;此时在bin目录下应该有ngrok和ngrokd两个可执行文件。&lt;/p&gt;

&lt;p&gt;如果需要交叉编译：先设置好GOOS与GOARCH变量&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Linux 平台 32 位系统：GOOS=linux GOARCH=386&lt;/p&gt;

&lt;p&gt;Linux 平台 64 位系统：GOOS=linux GOARCH=amd64&lt;/p&gt;

&lt;p&gt;Windows 平台 32 位系统：GOOS=windows GOARCH=386&lt;/p&gt;

&lt;p&gt;Windows 平台 64 位系统：GOOS=windows GOARCH=amd64&lt;/p&gt;

&lt;p&gt;MAC 平台 32 位系统：GOOS=darwin GOARCH=386&lt;/p&gt;

&lt;p&gt;MAC 平台 64 位系统：GOOS=darwin GOARCH=amd64&lt;/p&gt;

&lt;p&gt;如需要编译window 64位版本：
GOOS=windows GOARCH=amd64 make release-client&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;服务端启动：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;nohup ./bin/ngrokd -tlsKey=server.key -tlsCrt=server.crt -domain=&amp;ldquo;test.site&amp;rdquo; -httpAddr=&amp;rdquo;:8081&amp;rdquo; -httpsAddr=&amp;rdquo;:8082&amp;rdquo; &amp;amp;&lt;/p&gt;

&lt;p&gt;示例中8081用来连接http请求，8082用来连接https请求&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;客户端启动：&lt;/p&gt;

&lt;p&gt;将编译好的client版本下载到指定的机器上之后，配置启动文件：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;server_addr: test.site:4443			//4443为ngrok控制tunnel
trust_host_root_certs: false		//如果不需要使用TLS，可以将此变量设置为你false
tunnels:
  client:
    subdomain: pub
    proto:
      http: 8080
  ssh:
    remote_port: 2022
    proto:
      tcp: 22
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;./ngrok -log=stdout -config=ngrok.yml start ssh client&amp;amp;  启动客户端&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;此时，会把本机的8080端口的服务映射到服务端pub.test.site:8081端口，便可以用来访问客户端的8080端口的服务了。&lt;/p&gt;

&lt;p&gt;tcp tunnel将22端口映射到服务端的2022端口，便可以ssh user@test.site -p2022 来访问客户端的ssh服务了。&lt;/p&gt;

&lt;p&gt;开机启动ngrok client：&lt;/p&gt;

&lt;p&gt;首先编写启动脚本 ngrok.sh：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd /path/to/ngrok-client
./ngrok -log=stdout -config=ngrok.yml start ssh&amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再配置systemd ngrok service文件 /usr/lib/systemd/system/ngrok.service；&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Unit]
Description=ngrok service

[Service]
Type=forking
ExecStart=/bin/bash /path/to/ngrok.sh

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后，&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;systemctl enable ngrok.service
systemctl start ngrok.service
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;服务就可以开机启动了&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>
